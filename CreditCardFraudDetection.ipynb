{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e30a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit Card Fraud Detection\n",
    "# Performing CNN on the Credit Card Dataset, in order to determine if the transactions are fraud or not.\n",
    "# Library Used: TensorFlow, Sklearn, Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e235cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPool1D\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5058bcd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "data=pd.read_csv('C:/Users/User/Desktop/archive4.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b0f38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To determine the Data types of the features\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c41f7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "data.shape\n",
    "# There are 31 columns here, and the final column contains the Class target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac727a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get all the details\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fadfc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To determine if there is any null values present in the dataset\n",
    "data.isnull().sum()\n",
    "#Can be seen that there is no null value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e593ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#To get all the information about all the features\n",
    "data.info()\n",
    "#Can be determine by looking at the dataset and the information that our target column has values consisting 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e679c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of values in the \"class\" that have values of 0 or 1 that are present.\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb0a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 284315 transactions \n",
    "# 492 transactions are fraud only.\n",
    "# Now, balancing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125cc76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284315, 31), (492, 31))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating fraud and non-fraud rows\n",
    "nonFraudData = data[data['Class']==0]\n",
    "fraudData = data[data['Class']==1]\n",
    "\n",
    "nonFraudData.shape, fraudData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5bd3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the 492 non-fraud entries from the dataframe \n",
    "nonFraudDataSample = nonFraudData.sample(fraudData.shape[0])\n",
    "\n",
    "nonFraudDataSample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a59ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>46278.0</td>\n",
       "      <td>-1.324685</td>\n",
       "      <td>0.609745</td>\n",
       "      <td>1.410147</td>\n",
       "      <td>-1.221033</td>\n",
       "      <td>0.671130</td>\n",
       "      <td>-0.724581</td>\n",
       "      <td>1.316978</td>\n",
       "      <td>-0.454991</td>\n",
       "      <td>-0.625984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446117</td>\n",
       "      <td>-1.186777</td>\n",
       "      <td>-0.126134</td>\n",
       "      <td>0.027896</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>0.486834</td>\n",
       "      <td>-0.551385</td>\n",
       "      <td>-0.193366</td>\n",
       "      <td>59.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>190.0</td>\n",
       "      <td>-1.505779</td>\n",
       "      <td>-0.215325</td>\n",
       "      <td>1.991294</td>\n",
       "      <td>-1.631493</td>\n",
       "      <td>-0.635965</td>\n",
       "      <td>0.228414</td>\n",
       "      <td>-0.034266</td>\n",
       "      <td>0.042696</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101938</td>\n",
       "      <td>0.148146</td>\n",
       "      <td>-0.450115</td>\n",
       "      <td>-0.396558</td>\n",
       "      <td>0.554224</td>\n",
       "      <td>-0.340493</td>\n",
       "      <td>-0.335618</td>\n",
       "      <td>-0.413379</td>\n",
       "      <td>82.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>159453.0</td>\n",
       "      <td>2.073381</td>\n",
       "      <td>0.079111</td>\n",
       "      <td>-1.712217</td>\n",
       "      <td>0.435761</td>\n",
       "      <td>0.298314</td>\n",
       "      <td>-0.927336</td>\n",
       "      <td>0.107780</td>\n",
       "      <td>-0.173600</td>\n",
       "      <td>0.664751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376078</td>\n",
       "      <td>-1.031766</td>\n",
       "      <td>0.358219</td>\n",
       "      <td>0.536779</td>\n",
       "      <td>-0.300807</td>\n",
       "      <td>0.173544</td>\n",
       "      <td>-0.069973</td>\n",
       "      <td>-0.032708</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>168788.0</td>\n",
       "      <td>0.044763</td>\n",
       "      <td>0.328286</td>\n",
       "      <td>0.338364</td>\n",
       "      <td>-0.513338</td>\n",
       "      <td>-0.360077</td>\n",
       "      <td>0.622709</td>\n",
       "      <td>-0.431851</td>\n",
       "      <td>0.750770</td>\n",
       "      <td>0.300673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229420</td>\n",
       "      <td>0.530297</td>\n",
       "      <td>0.384635</td>\n",
       "      <td>0.298683</td>\n",
       "      <td>-1.158083</td>\n",
       "      <td>-0.028312</td>\n",
       "      <td>-0.058346</td>\n",
       "      <td>-0.030623</td>\n",
       "      <td>55.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>14633.0</td>\n",
       "      <td>-1.628306</td>\n",
       "      <td>-5.579608</td>\n",
       "      <td>-0.240473</td>\n",
       "      <td>-0.362378</td>\n",
       "      <td>-2.779254</td>\n",
       "      <td>1.427685</td>\n",
       "      <td>0.361396</td>\n",
       "      <td>0.194887</td>\n",
       "      <td>4.469269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727297</td>\n",
       "      <td>-0.209446</td>\n",
       "      <td>-1.320407</td>\n",
       "      <td>-0.217757</td>\n",
       "      <td>-0.026585</td>\n",
       "      <td>-0.782605</td>\n",
       "      <td>-0.125171</td>\n",
       "      <td>0.252385</td>\n",
       "      <td>1410.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "1       472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "2      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "3      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "4      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "979   46278.0 -1.324685  0.609745  1.410147 -1.221033  0.671130 -0.724581   \n",
       "980     190.0 -1.505779 -0.215325  1.991294 -1.631493 -0.635965  0.228414   \n",
       "981  159453.0  2.073381  0.079111 -1.712217  0.435761  0.298314 -0.927336   \n",
       "982  168788.0  0.044763  0.328286  0.338364 -0.513338 -0.360077  0.622709   \n",
       "983   14633.0 -1.628306 -5.579608 -0.240473 -0.362378 -2.779254  1.427685   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0   -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "1    0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "2    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "3   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "4    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "979  1.316978 -0.454991 -0.625984  ... -0.446117 -1.186777 -0.126134   \n",
       "980 -0.034266  0.042696 -0.235440  ... -0.101938  0.148146 -0.450115   \n",
       "981  0.107780 -0.173600  0.664751  ... -0.376078 -1.031766  0.358219   \n",
       "982 -0.431851  0.750770  0.300673  ...  0.229420  0.530297  0.384635   \n",
       "983  0.361396  0.194887  4.469269  ...  0.727297 -0.209446 -1.320407   \n",
       "\n",
       "          V24       V25       V26       V27       V28   Amount  Class  \n",
       "0    0.320198  0.044519  0.177840  0.261145 -0.143276     0.00      1  \n",
       "1   -0.293803  0.279798 -0.145362 -0.252773  0.035764   529.00      1  \n",
       "2   -0.087330 -0.156114 -0.542628  0.039566 -0.153029   239.93      1  \n",
       "3   -0.053502  0.252405 -0.657488 -0.827136  0.849573    59.00      1  \n",
       "4   -1.632653  1.488901  0.566797 -0.010016  0.146793     1.00      1  \n",
       "..        ...       ...       ...       ...       ...      ...    ...  \n",
       "979  0.027896  0.101104  0.486834 -0.551385 -0.193366    59.99      0  \n",
       "980 -0.396558  0.554224 -0.340493 -0.335618 -0.413379    82.29      0  \n",
       "981  0.536779 -0.300807  0.173544 -0.069973 -0.032708     0.99      0  \n",
       "982  0.298683 -1.158083 -0.028312 -0.058346 -0.030623    55.99      0  \n",
       "983 -0.217757 -0.026585 -0.782605 -0.125171  0.252385  1410.02      0  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now there is balanced dataset: rows 492 fraud , 492 non-fraud\n",
    "balancedData = fraudData.append(nonFraudDataSample,ignore_index = True) \n",
    "balancedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee4b34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the data has been balanced and combined.\n",
    "# Check again the value counts\n",
    "balancedData['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475b789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((984, 30), (984,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now dividing the dataframe into dependent and independent varaible\n",
    "x=balancedData.drop(['Class'], axis=1)\n",
    "y=balancedData.Class\n",
    "\n",
    "# check the shape\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9f901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738, 30) (246, 30) (738,) (246,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting in to Train and test dataset\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# Check the shape again\n",
    "print(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "sc=StandardScaler()\n",
    "xtrain=sc.fit_transform(xtrain)\n",
    "xtest=sc.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea10874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 2D dataset into 3D For CNN prediction\n",
    "# xtrain = xtrain.to_numpy()\n",
    "# xtest = xtest.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9979721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((738, 30, 1), (246, 30, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = xtrain.reshape(xtrain.shape[0],xtrain.shape[1],1)\n",
    "xtest = xtest.reshape(xtest.shape[0],xtest.shape[1],1)\n",
    "\n",
    "# Cheking the shape\n",
    "xtrain.shape, xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc74a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain, ytest are in series, converting the same into a numpy array\n",
    "ytrain=ytrain.to_numpy()\n",
    "ytest=ytest.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fedde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Model: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dde48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "model = Sequential()\n",
    "\n",
    "# layers:\n",
    "\n",
    "# 1) First\n",
    "# The model starts with adding a 1D convolutional layer with 32 filters,\n",
    "# kernel size of 2, a ReLU activation function, and input shape of the xtrain data.\n",
    "# It then applies batch normalization which normalize the activations of the previous layer at each batch.\n",
    "# The code then applies dropout with a rate of 0.2 to prevent overfitting.\n",
    "model.add(Conv1D(32, kernel_size=2, activation = 'relu',input_shape = xtrain[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98017285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Second\n",
    "# The code then adds another 1D convolutional layer with 64 filters,\n",
    "# kernel size of 2, a ReLU activation function, and applies batch normalization and dropout \n",
    "# with a rate of 0.5 again to prevent overfitting.\n",
    "model.add(Conv1D(64, kernel_size=2, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b67d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) building Artificial neural network (ANN)\n",
    "# Then the code flattens the output of the previous layer and add a dense layer with 64 units \n",
    "# and ReLU activation function, followed by dropout with a rate of 0.5 to prevent overfitting.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56b3d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Last\n",
    "# The code adds the last dense layer with 1 unit and a sigmoid activation function.\n",
    "# This layer is used as the output layer, and the activation function (sigmoid) is used for binary classification problems.\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe04dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 29, 32)            96        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 29, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 29, 32)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 28, 64)            4160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 64)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                114752    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,457\n",
      "Trainable params: 119,265\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#It shows the layers of the model, the number of parameters in each layer, \n",
    "#the shape of the output of each layer, and the total number of parameters in the model.\n",
    "#This is useful for understanding the structure of the model and for debugging.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5689a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "# We can change the lr during the training process.\n",
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a94075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "24/24 [==============================] - 2s 22ms/step - loss: 0.6166 - accuracy: 0.8306 - val_loss: 0.4893 - val_accuracy: 0.8902\n",
      "Epoch 2/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.2814 - accuracy: 0.9119 - val_loss: 0.5085 - val_accuracy: 0.5407\n",
      "Epoch 3/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.2355 - accuracy: 0.9214 - val_loss: 0.5080 - val_accuracy: 0.5366\n",
      "Epoch 4/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1906 - accuracy: 0.9336 - val_loss: 0.4365 - val_accuracy: 0.6667\n",
      "Epoch 5/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.9444 - val_loss: 0.4649 - val_accuracy: 0.5894\n",
      "Epoch 6/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.9444 - val_loss: 0.4957 - val_accuracy: 0.5650\n",
      "Epoch 7/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1742 - accuracy: 0.9390 - val_loss: 0.4632 - val_accuracy: 0.6098\n",
      "Epoch 8/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1428 - accuracy: 0.9485 - val_loss: 0.5511 - val_accuracy: 0.5732\n",
      "Epoch 9/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1530 - accuracy: 0.9404 - val_loss: 0.3699 - val_accuracy: 0.7967\n",
      "Epoch 10/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1200 - accuracy: 0.9634 - val_loss: 0.3049 - val_accuracy: 0.8821\n",
      "Epoch 11/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1517 - accuracy: 0.9539 - val_loss: 0.3298 - val_accuracy: 0.8496\n",
      "Epoch 12/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1357 - accuracy: 0.9526 - val_loss: 0.2307 - val_accuracy: 0.9309\n",
      "Epoch 13/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.9566 - val_loss: 0.2184 - val_accuracy: 0.9268\n",
      "Epoch 14/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 0.9539 - val_loss: 0.2596 - val_accuracy: 0.8943\n",
      "Epoch 15/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1184 - accuracy: 0.9539 - val_loss: 0.2241 - val_accuracy: 0.9268\n",
      "Epoch 16/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1275 - accuracy: 0.9526 - val_loss: 0.2037 - val_accuracy: 0.9350\n",
      "Epoch 17/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1240 - accuracy: 0.9499 - val_loss: 0.1853 - val_accuracy: 0.9268\n",
      "Epoch 18/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1226 - accuracy: 0.9580 - val_loss: 0.2033 - val_accuracy: 0.9350\n",
      "Epoch 19/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1364 - accuracy: 0.9512 - val_loss: 0.1941 - val_accuracy: 0.9228\n",
      "Epoch 20/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.9580 - val_loss: 0.1847 - val_accuracy: 0.9309\n",
      "Epoch 21/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.1111 - accuracy: 0.9512 - val_loss: 0.1721 - val_accuracy: 0.9309\n",
      "Epoch 22/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9621 - val_loss: 0.1795 - val_accuracy: 0.9390\n",
      "Epoch 23/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.9566 - val_loss: 0.1720 - val_accuracy: 0.9350\n",
      "Epoch 24/60\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1277 - accuracy: 0.9593 - val_loss: 0.2142 - val_accuracy: 0.9350\n",
      "Epoch 25/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0978 - accuracy: 0.9648 - val_loss: 0.2236 - val_accuracy: 0.9309\n",
      "Epoch 26/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0938 - accuracy: 0.9621 - val_loss: 0.2152 - val_accuracy: 0.9350\n",
      "Epoch 27/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 0.9688 - val_loss: 0.2229 - val_accuracy: 0.9268\n",
      "Epoch 28/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9661 - val_loss: 0.2342 - val_accuracy: 0.9350\n",
      "Epoch 29/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 0.9661 - val_loss: 0.2266 - val_accuracy: 0.9309\n",
      "Epoch 30/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0926 - accuracy: 0.9661 - val_loss: 0.2247 - val_accuracy: 0.9309\n",
      "Epoch 31/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9702 - val_loss: 0.2143 - val_accuracy: 0.9390\n",
      "Epoch 32/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 0.9715 - val_loss: 0.2177 - val_accuracy: 0.9350\n",
      "Epoch 33/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0814 - accuracy: 0.9675 - val_loss: 0.2231 - val_accuracy: 0.9390\n",
      "Epoch 34/60\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0863 - accuracy: 0.9675 - val_loss: 0.2187 - val_accuracy: 0.9309\n",
      "Epoch 35/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0963 - accuracy: 0.9661 - val_loss: 0.2365 - val_accuracy: 0.9390\n",
      "Epoch 36/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9648 - val_loss: 0.2524 - val_accuracy: 0.9350\n",
      "Epoch 37/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0946 - accuracy: 0.9621 - val_loss: 0.2479 - val_accuracy: 0.9350\n",
      "Epoch 38/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9688 - val_loss: 0.2658 - val_accuracy: 0.9390\n",
      "Epoch 39/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1046 - accuracy: 0.9621 - val_loss: 0.3352 - val_accuracy: 0.9309\n",
      "Epoch 40/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.9661 - val_loss: 0.3082 - val_accuracy: 0.9309\n",
      "Epoch 41/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9715 - val_loss: 0.3009 - val_accuracy: 0.9350\n",
      "Epoch 42/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 0.9797 - val_loss: 0.3086 - val_accuracy: 0.9350\n",
      "Epoch 43/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0852 - accuracy: 0.9675 - val_loss: 0.2795 - val_accuracy: 0.9268\n",
      "Epoch 44/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9743 - val_loss: 0.2723 - val_accuracy: 0.9350\n",
      "Epoch 45/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0644 - accuracy: 0.9743 - val_loss: 0.2620 - val_accuracy: 0.9390\n",
      "Epoch 46/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0883 - accuracy: 0.9634 - val_loss: 0.2759 - val_accuracy: 0.9309\n",
      "Epoch 47/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0851 - accuracy: 0.9648 - val_loss: 0.2668 - val_accuracy: 0.9390\n",
      "Epoch 48/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0682 - accuracy: 0.9824 - val_loss: 0.2785 - val_accuracy: 0.9350\n",
      "Epoch 49/60\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0795 - accuracy: 0.9729 - val_loss: 0.2767 - val_accuracy: 0.9472\n",
      "Epoch 50/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9797 - val_loss: 0.2903 - val_accuracy: 0.9431\n",
      "Epoch 51/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0608 - accuracy: 0.9783 - val_loss: 0.2901 - val_accuracy: 0.9431\n",
      "Epoch 52/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0638 - accuracy: 0.9770 - val_loss: 0.2865 - val_accuracy: 0.9390\n",
      "Epoch 53/60\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0696 - accuracy: 0.9743 - val_loss: 0.2908 - val_accuracy: 0.9390\n",
      "Epoch 54/60\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9688 - val_loss: 0.2841 - val_accuracy: 0.9431\n",
      "Epoch 55/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0737 - accuracy: 0.9688 - val_loss: 0.2568 - val_accuracy: 0.9390\n",
      "Epoch 56/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9715 - val_loss: 0.2711 - val_accuracy: 0.9350\n",
      "Epoch 57/60\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9797 - val_loss: 0.2789 - val_accuracy: 0.9390\n",
      "Epoch 58/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9810 - val_loss: 0.2935 - val_accuracy: 0.9350\n",
      "Epoch 59/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9756 - val_loss: 0.2881 - val_accuracy: 0.9309\n",
      "Epoch 60/60\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9743 - val_loss: 0.2910 - val_accuracy: 0.9350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d081277370>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It trains the model on the training data (X_train and y_train), for 20 epochs and also passing \n",
    "#the test data (X_test and y_test) as validation_data to evaluate performance after each epoch.\n",
    "model.fit(xtrain,ytrain, epochs=60, validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c49b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_acc = model.evaluate(xtest,ytest)\n",
    "#final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57360efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making the Prediction on a test set of data (xtest) and Evaluating the model\n",
    "yPrediction = model.predict(xtest)\n",
    "yPrediction = (yPrediction>0.5)#Converts the predicted probability values into binary values by using a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88671a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "ROC AUC: 0.961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get the predicted probability values for the positive class (class 1)\n",
    "yPredictionProb = model.predict(xtest)[:,0]\n",
    "# Calculate the ROC AUC score\n",
    "rocAUC = roc_auc_score(ytest, yPredictionProb)\n",
    "print(\"ROC AUC: {:.3f}\".format(rocAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52e2aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluating the accuracy score and confusion matrix\n",
    "# Checking the accuracy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "confMatrix = confusion_matrix(ytest, yPrediction)\n",
    "sns.heatmap(confMatrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08cd4eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.9349593495934959\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score : \", accuracy_score(ytest, yPrediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "186bc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5634270e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.90625    0.96610169]\n",
      "Recall: [0.96666667 0.9047619 ]\n",
      "Fscore: [0.93548387 0.93442623]\n",
      "Support: [120 126]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(ytest, yPrediction)\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('Fscore: {}'.format(fscore))\n",
    "print('Support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091e6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
