{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e30a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit Card Fraud Detection\n",
    "# Performing CNN on the Credit Card Dataset, in order to determine if the transactions are fraud or not.\n",
    "# Library Used: TensorFlow, Sklearn, Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e235cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPool1D\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5058bcd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "data=pd.read_csv('C:/Users/User/Desktop/archive4.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b0f38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To determine the Data types of the features\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c41f7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "data.shape\n",
    "# There are 31 columns here, and the final column contains the Class target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac727a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get all the details\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fadfc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To determine if there is any null values present in the dataset\n",
    "data.isnull().sum()\n",
    "#Can be seen that there is no null value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e593ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#To get all the information about all the features\n",
    "data.info()\n",
    "#Can be determine by looking at the dataset and the information that our target column has values consisting 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e679c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of values in the \"class\" that have values of 0 or 1 that are present.\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb0a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 284315 transactions \n",
    "# 492 transactions are fraud only.\n",
    "# Now, balancing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125cc76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284315, 31), (492, 31))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating fraud and non-fraud rows\n",
    "nonFraudData = data[data['Class']==0]\n",
    "fraudData = data[data['Class']==1]\n",
    "\n",
    "nonFraudData.shape, fraudData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5bd3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the 492 non-fraud entries from the dataframe \n",
    "nonFraudDataSample = nonFraudData.sample(fraudData.shape[0])\n",
    "\n",
    "nonFraudDataSample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a59ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>64075.0</td>\n",
       "      <td>1.111020</td>\n",
       "      <td>-0.072666</td>\n",
       "      <td>0.925315</td>\n",
       "      <td>1.562056</td>\n",
       "      <td>-0.586746</td>\n",
       "      <td>0.268497</td>\n",
       "      <td>-0.401192</td>\n",
       "      <td>0.189653</td>\n",
       "      <td>0.922774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086708</td>\n",
       "      <td>0.099533</td>\n",
       "      <td>-0.070265</td>\n",
       "      <td>0.087981</td>\n",
       "      <td>0.600571</td>\n",
       "      <td>-0.256842</td>\n",
       "      <td>0.070230</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>72240.0</td>\n",
       "      <td>1.219754</td>\n",
       "      <td>0.368057</td>\n",
       "      <td>0.324857</td>\n",
       "      <td>1.442379</td>\n",
       "      <td>-0.334085</td>\n",
       "      <td>-1.048428</td>\n",
       "      <td>0.312373</td>\n",
       "      <td>-0.249684</td>\n",
       "      <td>0.049149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015934</td>\n",
       "      <td>0.112052</td>\n",
       "      <td>-0.103748</td>\n",
       "      <td>0.737076</td>\n",
       "      <td>0.792607</td>\n",
       "      <td>-0.280876</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>82482.0</td>\n",
       "      <td>-5.944376</td>\n",
       "      <td>4.617413</td>\n",
       "      <td>-2.001718</td>\n",
       "      <td>-1.982703</td>\n",
       "      <td>-2.653444</td>\n",
       "      <td>-0.874220</td>\n",
       "      <td>-1.981014</td>\n",
       "      <td>3.021313</td>\n",
       "      <td>1.713123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174660</td>\n",
       "      <td>-0.470570</td>\n",
       "      <td>0.513265</td>\n",
       "      <td>-0.062049</td>\n",
       "      <td>0.359824</td>\n",
       "      <td>0.805723</td>\n",
       "      <td>0.853437</td>\n",
       "      <td>0.621119</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>99167.0</td>\n",
       "      <td>-2.380567</td>\n",
       "      <td>1.831206</td>\n",
       "      <td>-1.186275</td>\n",
       "      <td>-0.349462</td>\n",
       "      <td>-0.228867</td>\n",
       "      <td>-1.230816</td>\n",
       "      <td>-0.184015</td>\n",
       "      <td>0.889110</td>\n",
       "      <td>1.389572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.479449</td>\n",
       "      <td>-0.730975</td>\n",
       "      <td>0.593091</td>\n",
       "      <td>-0.217680</td>\n",
       "      <td>-0.167484</td>\n",
       "      <td>0.137827</td>\n",
       "      <td>0.093724</td>\n",
       "      <td>-0.028206</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>97196.0</td>\n",
       "      <td>-0.549148</td>\n",
       "      <td>0.135248</td>\n",
       "      <td>-0.951932</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>2.589040</td>\n",
       "      <td>-2.430699</td>\n",
       "      <td>0.965114</td>\n",
       "      <td>-0.887466</td>\n",
       "      <td>0.967196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024188</td>\n",
       "      <td>0.557475</td>\n",
       "      <td>-0.401049</td>\n",
       "      <td>-0.064476</td>\n",
       "      <td>-0.271528</td>\n",
       "      <td>0.117168</td>\n",
       "      <td>-0.101971</td>\n",
       "      <td>-0.148193</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "1      472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "2     4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "3     6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "4     7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "979  64075.0  1.111020 -0.072666  0.925315  1.562056 -0.586746  0.268497   \n",
       "980  72240.0  1.219754  0.368057  0.324857  1.442379 -0.334085 -1.048428   \n",
       "981  82482.0 -5.944376  4.617413 -2.001718 -1.982703 -2.653444 -0.874220   \n",
       "982  99167.0 -2.380567  1.831206 -1.186275 -0.349462 -0.228867 -1.230816   \n",
       "983  97196.0 -0.549148  0.135248 -0.951932  0.032096  2.589040 -2.430699   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0   -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "1    0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "2    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "3   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "4    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "979 -0.401192  0.189653  0.922774  ... -0.086708  0.099533 -0.070265   \n",
       "980  0.312373 -0.249684  0.049149  ... -0.015934  0.112052 -0.103748   \n",
       "981 -1.981014  3.021313  1.713123  ... -0.174660 -0.470570  0.513265   \n",
       "982 -0.184015  0.889110  1.389572  ... -0.479449 -0.730975  0.593091   \n",
       "983  0.965114 -0.887466  0.967196  ... -0.024188  0.557475 -0.401049   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1   -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3   -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4   -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "979  0.087981  0.600571 -0.256842  0.070230  0.022468   11.99      0  \n",
       "980  0.737076  0.792607 -0.280876  0.009116  0.016671    2.00      0  \n",
       "981 -0.062049  0.359824  0.805723  0.853437  0.621119    3.69      0  \n",
       "982 -0.217680 -0.167484  0.137827  0.093724 -0.028206    8.99      0  \n",
       "983 -0.064476 -0.271528  0.117168 -0.101971 -0.148193   12.00      0  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now there is balanced dataset: rows 492 fraud , 492 non-fraud\n",
    "balancedData = fraudData.append(nonFraudDataSample,ignore_index = True) \n",
    "balancedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee4b34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the data has been balanced and combined.\n",
    "# Check again the value counts\n",
    "balancedData['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475b789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((984, 30), (984,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now dividing the dataframe into dependent and independent varaible\n",
    "x=balancedData.drop(['Class'], axis=1)\n",
    "y=balancedData.Class\n",
    "\n",
    "# check the shape\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9f901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738, 30) (246, 30) (738,) (246,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting in to Train and test dataset\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# Check the shape again\n",
    "print(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "sc=StandardScaler()\n",
    "xtrain=sc.fit_transform(xtrain)\n",
    "xtest=sc.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea10874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 2D dataset into 3D For CNN prediction\n",
    "# xtrain = xtrain.to_numpy()\n",
    "# xtest = xtest.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9979721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((738, 30, 1), (246, 30, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = xtrain.reshape(xtrain.shape[0],xtrain.shape[1],1)\n",
    "xtest = xtest.reshape(xtest.shape[0],xtest.shape[1],1)\n",
    "\n",
    "# Cheking the shape\n",
    "xtrain.shape, xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc74a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytrain, ytest are in series, converting the same into a numpy array\n",
    "ytrain=ytrain.to_numpy()\n",
    "ytest=ytest.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fedde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Model: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dde48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "model = Sequential()\n",
    "\n",
    "# layers:\n",
    "\n",
    "# 1) First\n",
    "# The model starts with adding a 1D convolutional layer with 32 filters,\n",
    "# kernel size of 2, a ReLU activation function, and input shape of the xtrain data.\n",
    "# It then applies batch normalization which normalize the activations of the previous layer at each batch.\n",
    "# The code then applies dropout with a rate of 0.2 to prevent overfitting.\n",
    "model.add(Conv1D(32, kernel_size=2, activation = 'relu',input_shape = xtrain[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98017285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Second\n",
    "# The code then adds another 1D convolutional layer with 64 filters,\n",
    "# kernel size of 2, a ReLU activation function, and applies batch normalization and dropout \n",
    "# with a rate of 0.5 again to prevent overfitting.\n",
    "model.add(Conv1D(64, kernel_size=2, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b67d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) building Artificial neural network (ANN)\n",
    "# Then the code flattens the output of the previous layer and add a dense layer with 64 units \n",
    "# and ReLU activation function, followed by dropout with a rate of 0.5 to prevent overfitting.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56b3d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Last\n",
    "# The code adds the last dense layer with 1 unit and a sigmoid activation function.\n",
    "# This layer is used as the output layer, and the activation function (sigmoid) is used for binary classification problems.\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe04dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 29, 32)            96        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 29, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 29, 32)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 28, 64)            4160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 64)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1792)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                114752    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,457\n",
      "Trainable params: 119,265\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#It shows the layers of the model, the number of parameters in each layer, \n",
    "#the shape of the output of each layer, and the total number of parameters in the model.\n",
    "#This is useful for understanding the structure of the model and for debugging.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5689a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "# We can change the lr during the training process.\n",
    "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a94075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "24/24 [==============================] - 1s 17ms/step - loss: 0.4449 - accuracy: 0.8550 - val_loss: 0.5415 - val_accuracy: 0.6626\n",
      "Epoch 2/60\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2326 - accuracy: 0.9133 - val_loss: 0.5225 - val_accuracy: 0.5163\n",
      "Epoch 3/60\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9201 - val_loss: 0.5946 - val_accuracy: 0.5122\n",
      "Epoch 4/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1766 - accuracy: 0.9363 - val_loss: 0.5605 - val_accuracy: 0.5122\n",
      "Epoch 5/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1741 - accuracy: 0.9363 - val_loss: 0.4831 - val_accuracy: 0.5488\n",
      "Epoch 6/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9268 - val_loss: 0.5496 - val_accuracy: 0.5244\n",
      "Epoch 7/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.9417 - val_loss: 0.5731 - val_accuracy: 0.5122\n",
      "Epoch 8/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1418 - accuracy: 0.9472 - val_loss: 0.5339 - val_accuracy: 0.5569\n",
      "Epoch 9/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9431 - val_loss: 0.4743 - val_accuracy: 0.6301\n",
      "Epoch 10/60\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.9458 - val_loss: 0.4549 - val_accuracy: 0.6626\n",
      "Epoch 11/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1218 - accuracy: 0.9539 - val_loss: 0.3633 - val_accuracy: 0.8333\n",
      "Epoch 12/60\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.1435 - accuracy: 0.9607 - val_loss: 0.3829 - val_accuracy: 0.7846\n",
      "Epoch 13/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9593 - val_loss: 0.3619 - val_accuracy: 0.7967\n",
      "Epoch 14/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1109 - accuracy: 0.9593 - val_loss: 0.2755 - val_accuracy: 0.9024\n",
      "Epoch 15/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9485 - val_loss: 0.2769 - val_accuracy: 0.8984\n",
      "Epoch 16/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1154 - accuracy: 0.9526 - val_loss: 0.2181 - val_accuracy: 0.9350\n",
      "Epoch 17/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9526 - val_loss: 0.2023 - val_accuracy: 0.9350\n",
      "Epoch 18/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9553 - val_loss: 0.1746 - val_accuracy: 0.9228\n",
      "Epoch 19/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.9661 - val_loss: 0.1834 - val_accuracy: 0.9268\n",
      "Epoch 20/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9648 - val_loss: 0.1734 - val_accuracy: 0.9350\n",
      "Epoch 21/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9621 - val_loss: 0.1634 - val_accuracy: 0.9350\n",
      "Epoch 22/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.9634 - val_loss: 0.1558 - val_accuracy: 0.9431\n",
      "Epoch 23/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0927 - accuracy: 0.9621 - val_loss: 0.1500 - val_accuracy: 0.9472\n",
      "Epoch 24/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.1521 - val_accuracy: 0.9431\n",
      "Epoch 25/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9702 - val_loss: 0.1681 - val_accuracy: 0.9512\n",
      "Epoch 26/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0953 - accuracy: 0.9648 - val_loss: 0.1687 - val_accuracy: 0.9431\n",
      "Epoch 27/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9648 - val_loss: 0.1667 - val_accuracy: 0.9390\n",
      "Epoch 28/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.9634 - val_loss: 0.1644 - val_accuracy: 0.9431\n",
      "Epoch 29/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0854 - accuracy: 0.9688 - val_loss: 0.1620 - val_accuracy: 0.9431\n",
      "Epoch 30/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9756 - val_loss: 0.1578 - val_accuracy: 0.9431\n",
      "Epoch 31/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9715 - val_loss: 0.1608 - val_accuracy: 0.9472\n",
      "Epoch 32/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9729 - val_loss: 0.1547 - val_accuracy: 0.9390\n",
      "Epoch 33/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0959 - accuracy: 0.9593 - val_loss: 0.1580 - val_accuracy: 0.9350\n",
      "Epoch 34/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0759 - accuracy: 0.9702 - val_loss: 0.1657 - val_accuracy: 0.9431\n",
      "Epoch 35/60\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0811 - accuracy: 0.9702 - val_loss: 0.1715 - val_accuracy: 0.9350\n",
      "Epoch 36/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9702 - val_loss: 0.1735 - val_accuracy: 0.9390\n",
      "Epoch 37/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9688 - val_loss: 0.1950 - val_accuracy: 0.9390\n",
      "Epoch 38/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9783 - val_loss: 0.1807 - val_accuracy: 0.9390\n",
      "Epoch 39/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9729 - val_loss: 0.1725 - val_accuracy: 0.9431\n",
      "Epoch 40/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.1751 - val_accuracy: 0.9512\n",
      "Epoch 41/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9715 - val_loss: 0.1854 - val_accuracy: 0.9472\n",
      "Epoch 42/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0645 - accuracy: 0.9783 - val_loss: 0.1862 - val_accuracy: 0.9472\n",
      "Epoch 43/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9743 - val_loss: 0.2039 - val_accuracy: 0.9472\n",
      "Epoch 44/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9756 - val_loss: 0.2007 - val_accuracy: 0.9472\n",
      "Epoch 45/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9756 - val_loss: 0.1890 - val_accuracy: 0.9472\n",
      "Epoch 46/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 0.1916 - val_accuracy: 0.9390\n",
      "Epoch 47/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9743 - val_loss: 0.1930 - val_accuracy: 0.9268\n",
      "Epoch 48/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9783 - val_loss: 0.1889 - val_accuracy: 0.9431\n",
      "Epoch 49/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.1916 - val_accuracy: 0.9350\n",
      "Epoch 50/60\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9756 - val_loss: 0.1957 - val_accuracy: 0.9309\n",
      "Epoch 51/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9770 - val_loss: 0.1922 - val_accuracy: 0.9390\n",
      "Epoch 52/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.9715 - val_loss: 0.1905 - val_accuracy: 0.9472\n",
      "Epoch 53/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9783 - val_loss: 0.2003 - val_accuracy: 0.9472\n",
      "Epoch 54/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9715 - val_loss: 0.2068 - val_accuracy: 0.9350\n",
      "Epoch 55/60\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.2124 - val_accuracy: 0.9390\n",
      "Epoch 56/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.9770 - val_loss: 0.1995 - val_accuracy: 0.9350\n",
      "Epoch 57/60\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9783 - val_loss: 0.1819 - val_accuracy: 0.9309\n",
      "Epoch 58/60\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9743 - val_loss: 0.1855 - val_accuracy: 0.9309\n",
      "Epoch 59/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9797 - val_loss: 0.1819 - val_accuracy: 0.9431\n",
      "Epoch 60/60\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9770 - val_loss: 0.1861 - val_accuracy: 0.9350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f811ad940>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It trains the model on the training data (X_train and y_train), for 20 epochs and also passing \n",
    "#the test data (X_test and y_test) as validation_data to evaluate performance after each epoch.\n",
    "model.fit(xtrain,ytrain, epochs=60, validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57360efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making the Prediction on a test set of data (xtest) and Evaluating the model\n",
    "yPrediction = model.predict(xtest)\n",
    "yPrediction = (yPrediction>0.5)#Converts the predicted probability values into binary values by using a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88671a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "ROC AUC: 0.981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get the predicted probability values for the positive class (class 1)\n",
    "yPredictionProb = model.predict(xtest)[:,0]\n",
    "# Calculate the ROC AUC score\n",
    "rocAUC = roc_auc_score(ytest, yPredictionProb)\n",
    "print(\"ROC AUC: {:.3f}\".format(rocAUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52e2aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluating the accuracy score and confusion matrix\n",
    "# Checking the accuracy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotting the confusion matrix\n",
    "confMatrix = confusion_matrix(ytest, yPrediction)\n",
    "sns.heatmap(confMatrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "186bc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5634270e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.91935484 0.95081967]\n",
      "Recall: [0.95       0.92063492]\n",
      "Fscore: [0.93442623 0.93548387]\n",
      "Support: [120 126]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(ytest, yPrediction)\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('Fscore: {}'.format(fscore))\n",
    "print('Support: {}'.format(support))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
